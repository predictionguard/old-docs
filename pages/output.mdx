---
title: Validating LLM Output
description: Controlled and compliant AI applications
---

# Validating LLM Output

With Prediction Guard, you can control the output of LLMs in the following ways (which can be mixed and matched according to your use case and constraints):

- [Check for consistency](output/consistency)
- [Filter for factuality ](output/factuality)
- [Filter for toxicity](output/toxicity)
