---
title: Processing LLM input
description: Controlled and compliant AI applications
---

# Input Handling

With Prediction Guard, you get an extra layer of security that allows you to modify of personally identifiable information (PII) in incoming prompts and detect  injection attacks before the prompts hit the LLMs. 

- [Remove PII from incoming prompts](input/PII)
- [Detect prompt injections](input/injection)

