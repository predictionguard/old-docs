---
title: Processing LLM inpu
description: Controlled and compliant AI applications
---

# Validating LLM Output

With Prediction Guard, you get an extra layer of security that enables you to modify of personally identifiable information (PII) in incoming prompts and detection of injection attacks before the prompts hit the LLMs. 

- [Remove PII from incoming prompts](input/PII)
- [Detect prompt injections](input/injection)

